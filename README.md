# ğŸ¯ Web Crawler Toolkit

ğŸ•·ï¸ **Web Crawler Toolkit**, dinamik ve kompleks web sitelerinden (Ã¶rneÄŸin: **Biletix**, **Etkinlik siteleri**, **JS-heavy sayfalar**) veri Ã§ekmek isteyenler iÃ§in hazÄ±r Python betiklerinden oluÅŸan modern bir araÃ§ kutusudur.

KarmaÅŸÄ±k DOM yapÄ±larÄ±, JavaScript-render edilmiÅŸ iÃ§erikler, pagination ve sitemap analizi gibi birÃ§ok gerÃ§ek dÃ¼nya problemini hedefler.

---

## ğŸ“ Ä°Ã§erik

| Dosya                           | AÃ§Ä±klama |
|--------------------------------|----------|
| `biletix_event_scraper.py`     | Biletix gibi JavaScript tabanlÄ± sitelerden etkinlik bilgisi Ã§eker (Selenium ile). |
| `dynamic_scraper_selenium.py` | JavaScript iÃ§eriÄŸi yÃ¼kleyen tÃ¼m siteler iÃ§in genel dinamik scraper |
| `sitemap_parser.py`           | XML sitemap dosyalarÄ±ndan link Ã§Ä±karÄ±r |
| `simple_static_scraper.py`    | Basit HTML sayfalarÄ±ndan veri Ã§eker (requests + BeautifulSoup) |
| `utils/headers.py`            | Header spoofing, User-Agent randomizer |

---

## ğŸš€ Hedeflenen Senaryolar

- ğŸ« **Etkinlik sitelerinden** (Ã¶r. Biletix) etkinlik adÄ±, tarih ve yer Ã§ekme
- ğŸ§­ **Sitemap Ã¼zerinden** tÃ¼m sayfalarÄ± keÅŸfetme
- ğŸ•µï¸â€â™‚ï¸ JavaScript ile render edilen sayfalardan bilgi Ã§Ä±karma
- â³ Otomatik sayfa kaydÄ±rmalÄ± ve tÄ±klamalÄ± gezintiler

---

## âš™ï¸ Kurulum

Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼klemek iÃ§in:

```bash
pip install -r requirements.txt
